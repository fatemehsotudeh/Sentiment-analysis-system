{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from helpers import *\n",
    "from feature_extraction import *\n",
    "from modeling import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Tweet ID       entity sentiment  \\\n0      2401  Borderlands  Positive   \n1      2401  Borderlands  Positive   \n2      2401  Borderlands  Positive   \n3      2401  Borderlands  Positive   \n4      2401  Borderlands  Positive   \n\n                                       Tweet content  \\\n0  im getting on borderlands and i will murder yo...   \n1  I am coming to the borders and I will kill you...   \n2  im getting on borderlands and i will kill you ...   \n3  im coming on borderlands and i will murder you...   \n4  im getting on borderlands 2 and i will murder ...   \n\n  Preprocessed Tweet content  \n0   im get borderland murder  \n1           come border kill  \n2     im get borderland kill  \n3  im come borderland murder  \n4   im get borderland murder  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet ID</th>\n      <th>entity</th>\n      <th>sentiment</th>\n      <th>Tweet content</th>\n      <th>Preprocessed Tweet content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>im get borderland murder</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>come border kill</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>im get borderland kill</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>im come borderland murder</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>im get borderland murder</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../data/processed_data/'\n",
    "df_train = read_file(base_path + 'preprocessed_training_tweets.csv')\n",
    "df_test = read_file(base_path + 'preprocessed_test_tweets.csv')\n",
    "df_validation = read_file(base_path + 'preprocessed_validation_tweets.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Drop nan values (after preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=['Preprocessed Tweet content'])\n",
    "df_test = df_test.dropna(subset=['Preprocessed Tweet content'])\n",
    "df_validation = df_validation.dropna(subset=['Preprocessed Tweet content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Text Vectorization\n",
    "- Bag of Words\n",
    "- TF-IDF\n",
    "- Word2Vec\n",
    "- GloVe\n",
    "- FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1- Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<72310x33350 sparse matrix of type '<class 'numpy.int64'>'\n\twith 747231 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow, X_val_bow, X_test_bow = vectorize_bow(df_train['Preprocessed Tweet content'], df_validation['Preprocessed Tweet content'], df_test['Preprocessed Tweet content'])\n",
    "X_train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<72310x33350 sparse matrix of type '<class 'numpy.float64'>'\n\twith 747231 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf = vectorize_tfidf(df_train['Preprocessed Tweet content'], df_validation['Preprocessed Tweet content'], df_test['Preprocessed Tweet content'])\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3- Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# X_train_word2vec, X_val_word2vec, X_test_word2vec = vectorize_word2vec_data(df_train['Tweet content'], df_validation['Tweet content'], df_test['Tweet content'])\n",
    "# X_train_word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4- GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.16185583,  0.07815364,  0.12150591, ..., -0.23421918,\n        -0.03753255,  0.14226   ],\n       [ 0.35839301,  0.08509   ,  0.13379246, ..., -0.22806492,\n        -0.10831277,  0.21318831],\n       [ 0.21978219,  0.00331909,  0.28728227, ..., -0.24701373,\n        -0.07912255,  0.17095545],\n       ...,\n       [ 0.2251264 ,  0.04810692,  0.2021436 , ..., -0.19074525,\n         0.05156472, -0.08938948],\n       [ 0.20418338,  0.03497481,  0.26873603, ..., -0.21134004,\n         0.02856181, -0.05868534],\n       [ 0.28219232,  0.1075846 ,  0.13965788, ..., -0.21725121,\n         0.02088072, -0.0263792 ]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model = load_glove_model('../models/glove.6B.50d.txt')\n",
    "X_train_glove, X_val_glove, X_test_glove = vectorize_glove(df_train['Tweet content'], df_validation['Tweet content'], df_test['Tweet content'], glove_model)\n",
    "X_train_glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Train SVM model\n",
    "\n",
    "-using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_model_bow = train_svm_model(X_train_bow, df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using Bag Of Words\n",
      "Accuracy: 0.9218436873747495\n",
      "Confusion Matrix:\n",
      " [[ 84   3   0   5]\n",
      " [  3 115   3   4]\n",
      " [  0   3 126   5]\n",
      " [  6   4   3 135]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.90      0.91      0.91        92\n",
      "    Negative       0.92      0.92      0.92       125\n",
      "     Neutral       0.95      0.94      0.95       134\n",
      "    Positive       0.91      0.91      0.91       148\n",
      "\n",
      "    accuracy                           0.92       499\n",
      "   macro avg       0.92      0.92      0.92       499\n",
      "weighted avg       0.92      0.92      0.92       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=svm_model_bow.predict(X_test_bow)\n",
    "print(\"SVM using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "svm_model_tf_idf = train_svm_model(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using tf-idf\n",
      "Accuracy: 0.8957915831663327\n",
      "Confusion Matrix:\n",
      " [[ 83   4   0   5]\n",
      " [  3 113   4   5]\n",
      " [  3   8 116   7]\n",
      " [  7   3   3 135]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.86      0.90      0.88        92\n",
      "    Negative       0.88      0.90      0.89       125\n",
      "     Neutral       0.94      0.87      0.90       134\n",
      "    Positive       0.89      0.91      0.90       148\n",
      "\n",
      "    accuracy                           0.90       499\n",
      "   macro avg       0.89      0.90      0.89       499\n",
      "weighted avg       0.90      0.90      0.90       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=svm_model_tf_idf.predict(X_test_bow)\n",
    "print(\"SVM using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "svm_model_glove = train_svm_model(X_train_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using glove\n",
      "Accuracy: 0.45691382765531063\n",
      "Confusion Matrix:\n",
      " [[ 3 28 23 38]\n",
      " [ 0 91 20 14]\n",
      " [ 2 47 48 37]\n",
      " [ 2 36 24 86]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.43      0.03      0.06        92\n",
      "    Negative       0.45      0.73      0.56       125\n",
      "     Neutral       0.42      0.36      0.39       134\n",
      "    Positive       0.49      0.58      0.53       148\n",
      "\n",
      "    accuracy                           0.46       499\n",
      "   macro avg       0.45      0.42      0.38       499\n",
      "weighted avg       0.45      0.46      0.41       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=svm_model_glove.predict(X_test_glove)\n",
    "print(\"SVM using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train naive bayes model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using Bag of Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "naive_bayes_model_bow = train_naive_bayes(X_train_bow, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes using Bag Of Words\n",
      "Accuracy: 0.7715430861723447\n",
      "Confusion Matrix:\n",
      " [[ 65  14   2  11]\n",
      " [  2 107   6  10]\n",
      " [  9  20  92  13]\n",
      " [  7  13   7 121]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.78      0.71      0.74        92\n",
      "    Negative       0.69      0.86      0.77       125\n",
      "     Neutral       0.86      0.69      0.76       134\n",
      "    Positive       0.78      0.82      0.80       148\n",
      "\n",
      "    accuracy                           0.77       499\n",
      "   macro avg       0.78      0.77      0.77       499\n",
      "weighted avg       0.78      0.77      0.77       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=naive_bayes_model_bow.predict(X_test_bow)\n",
    "print(\"naive bayes using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "naive_bayes_model_tf_idf = train_naive_bayes(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes using tf-idf\n",
      "Accuracy: 0.7675350701402806\n",
      "Confusion Matrix:\n",
      " [[ 54  21   2  15]\n",
      " [  0 115   2   8]\n",
      " [  2  29  86  17]\n",
      " [  4  12   4 128]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.90      0.59      0.71        92\n",
      "    Negative       0.65      0.92      0.76       125\n",
      "     Neutral       0.91      0.64      0.75       134\n",
      "    Positive       0.76      0.86      0.81       148\n",
      "\n",
      "    accuracy                           0.77       499\n",
      "   macro avg       0.81      0.75      0.76       499\n",
      "weighted avg       0.80      0.77      0.76       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=naive_bayes_model_tf_idf.predict(X_test_tfidf)\n",
    "print(\"naive bayes using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "X_train_scaled_glove, X_test_scaled_glove= scaler_data(X_train_glove, X_test_glove)\n",
    "naive_bayes_model_glove = train_naive_bayes(X_train_scaled_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes using glove\n",
      "Accuracy: 0.250501002004008\n",
      "Confusion Matrix:\n",
      " [[  0  92   0   0]\n",
      " [  0 125   0   0]\n",
      " [  0 134   0   0]\n",
      " [  0 148   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00        92\n",
      "    Negative       0.25      1.00      0.40       125\n",
      "     Neutral       0.00      0.00      0.00       134\n",
      "    Positive       0.00      0.00      0.00       148\n",
      "\n",
      "    accuracy                           0.25       499\n",
      "   macro avg       0.06      0.25      0.10       499\n",
      "weighted avg       0.06      0.25      0.10       499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=naive_bayes_model_glove.predict(X_test_scaled_glove)\n",
    "print(\"naive bayes using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train logistic regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using bag of words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_bow = train_logistic_regression(X_train_bow, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression using Bag Of Words\n",
      "Accuracy: 0.8997995991983968\n",
      "Confusion Matrix:\n",
      " [[ 80   3   1   8]\n",
      " [  5 113   4   3]\n",
      " [  0   5 123   6]\n",
      " [  7   5   3 133]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.87      0.87      0.87        92\n",
      "    Negative       0.90      0.90      0.90       125\n",
      "     Neutral       0.94      0.92      0.93       134\n",
      "    Positive       0.89      0.90      0.89       148\n",
      "\n",
      "    accuracy                           0.90       499\n",
      "   macro avg       0.90      0.90      0.90       499\n",
      "weighted avg       0.90      0.90      0.90       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=logistic_regression_model_bow.predict(X_test_bow)\n",
    "print(\"logistic regression using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_tf_idf = train_logistic_regression(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression using tf-idf\n",
      "Accuracy: 0.8777555110220441\n",
      "Confusion Matrix:\n",
      " [[ 77   7   2   6]\n",
      " [  4 112   5   4]\n",
      " [  7   6 117   4]\n",
      " [  8   3   5 132]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.80      0.84      0.82        92\n",
      "    Negative       0.88      0.90      0.89       125\n",
      "     Neutral       0.91      0.87      0.89       134\n",
      "    Positive       0.90      0.89      0.90       148\n",
      "\n",
      "    accuracy                           0.88       499\n",
      "   macro avg       0.87      0.87      0.87       499\n",
      "weighted avg       0.88      0.88      0.88       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=logistic_regression_model_tf_idf.predict(X_test_tfidf)\n",
    "print(\"logistic regression using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_glove = train_logistic_regression(X_train_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression using glove\n",
      "Accuracy: 0.46292585170340683\n",
      "Confusion Matrix:\n",
      " [[ 8 25 21 38]\n",
      " [ 1 86 21 17]\n",
      " [ 4 41 54 35]\n",
      " [ 5 32 28 83]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.44      0.09      0.15        92\n",
      "    Negative       0.47      0.69      0.56       125\n",
      "     Neutral       0.44      0.40      0.42       134\n",
      "    Positive       0.48      0.56      0.52       148\n",
      "\n",
      "    accuracy                           0.46       499\n",
      "   macro avg       0.46      0.43      0.41       499\n",
      "weighted avg       0.46      0.46      0.43       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=logistic_regression_model_glove.predict(X_test_glove)\n",
    "print(\"logistic regression using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using bag of words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "knn_model_bow = train_knn(X_train_bow, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn using Bag Of Words\n",
      "Accuracy: 0.9719438877755511\n",
      "Confusion Matrix:\n",
      " [[ 88   1   0   3]\n",
      " [  0 124   0   1]\n",
      " [  3   1 129   1]\n",
      " [  2   1   1 144]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.95      0.96      0.95        92\n",
      "    Negative       0.98      0.99      0.98       125\n",
      "     Neutral       0.99      0.96      0.98       134\n",
      "    Positive       0.97      0.97      0.97       148\n",
      "\n",
      "    accuracy                           0.97       499\n",
      "   macro avg       0.97      0.97      0.97       499\n",
      "weighted avg       0.97      0.97      0.97       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=knn_model_bow.predict(X_test_bow)\n",
    "print(\"knn using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "knn_model_tf_idf = train_knn(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn using tf-idf\n",
      "Accuracy: 0.9458917835671342\n",
      "Confusion Matrix:\n",
      " [[ 90   1   0   1]\n",
      " [  1 123   0   1]\n",
      " [  7   1 126   0]\n",
      " [ 13   2   0 133]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.81      0.98      0.89        92\n",
      "    Negative       0.97      0.98      0.98       125\n",
      "     Neutral       1.00      0.94      0.97       134\n",
      "    Positive       0.99      0.90      0.94       148\n",
      "\n",
      "    accuracy                           0.95       499\n",
      "   macro avg       0.94      0.95      0.94       499\n",
      "weighted avg       0.95      0.95      0.95       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=knn_model_tf_idf.predict(X_test_tfidf)\n",
    "print(\"knn using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "knn_model_glove = train_knn(X_train_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn using glove\n",
      "Accuracy: 0.8657314629258517\n",
      "Confusion Matrix:\n",
      " [[ 74   4   8   6]\n",
      " [  5 114   5   1]\n",
      " [  6   3 116   9]\n",
      " [  8   5   7 128]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.80      0.80      0.80        92\n",
      "    Negative       0.90      0.91      0.91       125\n",
      "     Neutral       0.85      0.87      0.86       134\n",
      "    Positive       0.89      0.86      0.88       148\n",
      "\n",
      "    accuracy                           0.87       499\n",
      "   macro avg       0.86      0.86      0.86       499\n",
      "weighted avg       0.87      0.87      0.87       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=knn_model_glove.predict(X_test_glove)\n",
    "print(\"knn using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
