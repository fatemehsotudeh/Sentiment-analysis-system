{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from helpers import *\n",
    "from feature_extraction import *\n",
    "from modeling import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Tweet ID       entity sentiment  \\\n0      2401  Borderlands  Positive   \n1      2401  Borderlands  Positive   \n2      2401  Borderlands  Positive   \n3      2401  Borderlands  Positive   \n4      2401  Borderlands  Positive   \n\n                                       Tweet content  \\\n0  im getting on borderlands and i will murder yo...   \n1  I am coming to the borders and I will kill you...   \n2  im getting on borderlands and i will kill you ...   \n3  im coming on borderlands and i will murder you...   \n4  im getting on borderlands 2 and i will murder ...   \n\n  Preprocessed Tweet content  \n0   im get borderland murder  \n1           come border kill  \n2     im get borderland kill  \n3  im come borderland murder  \n4   im get borderland murder  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet ID</th>\n      <th>entity</th>\n      <th>sentiment</th>\n      <th>Tweet content</th>\n      <th>Preprocessed Tweet content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>im get borderland murder</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>come border kill</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>im get borderland kill</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>im come borderland murder</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>im get borderland murder</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../data/processed_data/'\n",
    "df_train = read_file(base_path + 'preprocessed_training_tweets.csv')\n",
    "df_test = read_file(base_path + 'preprocessed_test_tweets.csv')\n",
    "df_validation = read_file(base_path + 'preprocessed_validation_tweets.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Drop nan values (after preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=['Preprocessed Tweet content'])\n",
    "df_test = df_test.dropna(subset=['Preprocessed Tweet content'])\n",
    "df_validation = df_validation.dropna(subset=['Preprocessed Tweet content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Text Vectorization\n",
    "- Bag of Words\n",
    "- TF-IDF\n",
    "- Word2Vec\n",
    "- GloVe\n",
    "- FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1- Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<72310x33350 sparse matrix of type '<class 'numpy.int64'>'\n\twith 747231 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow, X_val_bow, X_test_bow = vectorize_bow(df_train['Preprocessed Tweet content'], df_validation['Preprocessed Tweet content'], df_test['Preprocessed Tweet content'])\n",
    "X_train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<72310x33350 sparse matrix of type '<class 'numpy.float64'>'\n\twith 747231 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf = vectorize_tfidf(df_train['Preprocessed Tweet content'], df_validation['Preprocessed Tweet content'], df_test['Preprocessed Tweet content'])\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3- Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6   \\\n0      0.014036  0.430571  0.539577 -0.639534  0.169186 -0.674001 -0.196263   \n1      0.003110  0.609597  0.509721  0.255386  0.184877 -1.175817 -0.059922   \n2      0.046008  0.544611  0.573684 -0.694496  0.111231 -0.978861 -0.098933   \n3      0.017449  0.575258  0.526059 -0.458798  0.180068 -0.963977 -0.360158   \n4      0.014036  0.430571  0.539577 -0.639534  0.169186 -0.674001 -0.196263   \n...         ...       ...       ...       ...       ...       ...       ...   \n72305  0.380933  0.731974  0.282214  0.290113  0.624013 -0.441692 -0.174329   \n72306  0.426381  0.711457  0.193117  0.227430  0.649964 -0.512596 -0.282753   \n72307  0.379662  0.683923  0.215349  0.269714  0.643403 -0.451711 -0.241157   \n72308  0.343226  0.999473  0.388349  0.234204  0.605790 -0.542341 -0.158048   \n72309  0.394906  0.760885  0.307833  0.221061  0.505652 -0.465994 -0.144703   \n\n             7         8         9   ...        90        91        92  \\\n0      1.268145 -0.705653 -0.638094  ...  0.139400 -0.132278  0.427559   \n1      0.602043 -0.376292 -0.663746  ...  0.174276  0.272716  0.337077   \n2      1.243091 -0.972191 -0.676963  ...  0.349270 -0.135414  0.413543   \n3      1.062833 -0.214202 -0.654413  ... -0.238597  0.028587  0.389649   \n4      1.268145 -0.705653 -0.638094  ...  0.139400 -0.132278  0.427559   \n...         ...       ...       ...  ...       ...       ...       ...   \n72305  1.056800 -0.558692 -0.436377  ...  0.408003  0.355734  0.633011   \n72306  1.186269 -0.530241 -0.503277  ...  0.327798  0.343191  0.633612   \n72307  1.128227 -0.520607 -0.494656  ...  0.373588  0.345824  0.601870   \n72308  1.087535 -0.608297 -0.535299  ...  0.457798  0.336251  0.458279   \n72309  0.960274 -0.597708 -0.320623  ...  0.329853  0.297317  0.483177   \n\n             93        94        95        96        97        98        99  \n0      0.751168  0.187882  0.026096 -0.011868 -0.320428  0.818503 -0.103725  \n1      0.474314  0.456278  0.718474 -0.375157  0.233253  0.383640  0.570185  \n2      0.611177  0.286102  0.157505 -0.100442 -0.230821  0.858332 -0.009552  \n3      0.991787  0.037014  0.211681  0.037916 -0.027362  0.736385  0.433018  \n4      0.751168  0.187882  0.026096 -0.011868 -0.320428  0.818503 -0.103725  \n...         ...       ...       ...       ...       ...       ...       ...  \n72305  0.062165  0.758302  0.086660 -0.263412  0.112832  0.422880 -0.171908  \n72306  0.078843  0.734912  0.057234 -0.266654 -0.009306  0.439189 -0.238179  \n72307  0.074338  0.722378  0.072142 -0.288318 -0.039966  0.404217 -0.202219  \n72308  0.131583  0.748805 -0.155759 -0.166874  0.125870  0.468222 -0.189956  \n72309  0.168218  0.710531  0.003267 -0.173092  0.206607  0.588870 -0.120136  \n\n[72310 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.014036</td>\n      <td>0.430571</td>\n      <td>0.539577</td>\n      <td>-0.639534</td>\n      <td>0.169186</td>\n      <td>-0.674001</td>\n      <td>-0.196263</td>\n      <td>1.268145</td>\n      <td>-0.705653</td>\n      <td>-0.638094</td>\n      <td>...</td>\n      <td>0.139400</td>\n      <td>-0.132278</td>\n      <td>0.427559</td>\n      <td>0.751168</td>\n      <td>0.187882</td>\n      <td>0.026096</td>\n      <td>-0.011868</td>\n      <td>-0.320428</td>\n      <td>0.818503</td>\n      <td>-0.103725</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.003110</td>\n      <td>0.609597</td>\n      <td>0.509721</td>\n      <td>0.255386</td>\n      <td>0.184877</td>\n      <td>-1.175817</td>\n      <td>-0.059922</td>\n      <td>0.602043</td>\n      <td>-0.376292</td>\n      <td>-0.663746</td>\n      <td>...</td>\n      <td>0.174276</td>\n      <td>0.272716</td>\n      <td>0.337077</td>\n      <td>0.474314</td>\n      <td>0.456278</td>\n      <td>0.718474</td>\n      <td>-0.375157</td>\n      <td>0.233253</td>\n      <td>0.383640</td>\n      <td>0.570185</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.046008</td>\n      <td>0.544611</td>\n      <td>0.573684</td>\n      <td>-0.694496</td>\n      <td>0.111231</td>\n      <td>-0.978861</td>\n      <td>-0.098933</td>\n      <td>1.243091</td>\n      <td>-0.972191</td>\n      <td>-0.676963</td>\n      <td>...</td>\n      <td>0.349270</td>\n      <td>-0.135414</td>\n      <td>0.413543</td>\n      <td>0.611177</td>\n      <td>0.286102</td>\n      <td>0.157505</td>\n      <td>-0.100442</td>\n      <td>-0.230821</td>\n      <td>0.858332</td>\n      <td>-0.009552</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.017449</td>\n      <td>0.575258</td>\n      <td>0.526059</td>\n      <td>-0.458798</td>\n      <td>0.180068</td>\n      <td>-0.963977</td>\n      <td>-0.360158</td>\n      <td>1.062833</td>\n      <td>-0.214202</td>\n      <td>-0.654413</td>\n      <td>...</td>\n      <td>-0.238597</td>\n      <td>0.028587</td>\n      <td>0.389649</td>\n      <td>0.991787</td>\n      <td>0.037014</td>\n      <td>0.211681</td>\n      <td>0.037916</td>\n      <td>-0.027362</td>\n      <td>0.736385</td>\n      <td>0.433018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.014036</td>\n      <td>0.430571</td>\n      <td>0.539577</td>\n      <td>-0.639534</td>\n      <td>0.169186</td>\n      <td>-0.674001</td>\n      <td>-0.196263</td>\n      <td>1.268145</td>\n      <td>-0.705653</td>\n      <td>-0.638094</td>\n      <td>...</td>\n      <td>0.139400</td>\n      <td>-0.132278</td>\n      <td>0.427559</td>\n      <td>0.751168</td>\n      <td>0.187882</td>\n      <td>0.026096</td>\n      <td>-0.011868</td>\n      <td>-0.320428</td>\n      <td>0.818503</td>\n      <td>-0.103725</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72305</th>\n      <td>0.380933</td>\n      <td>0.731974</td>\n      <td>0.282214</td>\n      <td>0.290113</td>\n      <td>0.624013</td>\n      <td>-0.441692</td>\n      <td>-0.174329</td>\n      <td>1.056800</td>\n      <td>-0.558692</td>\n      <td>-0.436377</td>\n      <td>...</td>\n      <td>0.408003</td>\n      <td>0.355734</td>\n      <td>0.633011</td>\n      <td>0.062165</td>\n      <td>0.758302</td>\n      <td>0.086660</td>\n      <td>-0.263412</td>\n      <td>0.112832</td>\n      <td>0.422880</td>\n      <td>-0.171908</td>\n    </tr>\n    <tr>\n      <th>72306</th>\n      <td>0.426381</td>\n      <td>0.711457</td>\n      <td>0.193117</td>\n      <td>0.227430</td>\n      <td>0.649964</td>\n      <td>-0.512596</td>\n      <td>-0.282753</td>\n      <td>1.186269</td>\n      <td>-0.530241</td>\n      <td>-0.503277</td>\n      <td>...</td>\n      <td>0.327798</td>\n      <td>0.343191</td>\n      <td>0.633612</td>\n      <td>0.078843</td>\n      <td>0.734912</td>\n      <td>0.057234</td>\n      <td>-0.266654</td>\n      <td>-0.009306</td>\n      <td>0.439189</td>\n      <td>-0.238179</td>\n    </tr>\n    <tr>\n      <th>72307</th>\n      <td>0.379662</td>\n      <td>0.683923</td>\n      <td>0.215349</td>\n      <td>0.269714</td>\n      <td>0.643403</td>\n      <td>-0.451711</td>\n      <td>-0.241157</td>\n      <td>1.128227</td>\n      <td>-0.520607</td>\n      <td>-0.494656</td>\n      <td>...</td>\n      <td>0.373588</td>\n      <td>0.345824</td>\n      <td>0.601870</td>\n      <td>0.074338</td>\n      <td>0.722378</td>\n      <td>0.072142</td>\n      <td>-0.288318</td>\n      <td>-0.039966</td>\n      <td>0.404217</td>\n      <td>-0.202219</td>\n    </tr>\n    <tr>\n      <th>72308</th>\n      <td>0.343226</td>\n      <td>0.999473</td>\n      <td>0.388349</td>\n      <td>0.234204</td>\n      <td>0.605790</td>\n      <td>-0.542341</td>\n      <td>-0.158048</td>\n      <td>1.087535</td>\n      <td>-0.608297</td>\n      <td>-0.535299</td>\n      <td>...</td>\n      <td>0.457798</td>\n      <td>0.336251</td>\n      <td>0.458279</td>\n      <td>0.131583</td>\n      <td>0.748805</td>\n      <td>-0.155759</td>\n      <td>-0.166874</td>\n      <td>0.125870</td>\n      <td>0.468222</td>\n      <td>-0.189956</td>\n    </tr>\n    <tr>\n      <th>72309</th>\n      <td>0.394906</td>\n      <td>0.760885</td>\n      <td>0.307833</td>\n      <td>0.221061</td>\n      <td>0.505652</td>\n      <td>-0.465994</td>\n      <td>-0.144703</td>\n      <td>0.960274</td>\n      <td>-0.597708</td>\n      <td>-0.320623</td>\n      <td>...</td>\n      <td>0.329853</td>\n      <td>0.297317</td>\n      <td>0.483177</td>\n      <td>0.168218</td>\n      <td>0.710531</td>\n      <td>0.003267</td>\n      <td>-0.173092</td>\n      <td>0.206607</td>\n      <td>0.588870</td>\n      <td>-0.120136</td>\n    </tr>\n  </tbody>\n</table>\n<p>72310 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_word2vec= vectorize_word2vec_data(df_train['Preprocessed Tweet content'])\n",
    "X_val_word2vec= vectorize_word2vec_data(df_validation['Preprocessed Tweet content'])\n",
    "X_test_word2vec= vectorize_word2vec_data(df_test['Preprocessed Tweet content'])\n",
    "X_train_word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4- GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.098708  ,  0.024415  ,  0.2143875 , ..., -0.27250675,\n         0.18058433,  0.10823   ],\n       [ 0.64638   , -0.31335667,  0.49528967, ..., -0.071779  ,\n        -0.14538   , -0.32737267],\n       [ 0.2580055 , -0.18138   ,  0.6702725 , ..., -0.30769175,\n         0.06621182,  0.1871425 ],\n       ...,\n       [ 0.02429973, -0.05667118,  0.47029909, ..., -0.12513364,\n         0.368412  , -0.10008964],\n       [ 0.00721407, -0.08955614,  0.44675443, ..., -0.21374929,\n         0.32166086, -0.09875436],\n       [ 0.12131609,  0.04995064,  0.25476455, ..., -0.28956455,\n         0.26706018, -0.04971727]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model = load_glove_model('../models/glove.6B.50d.txt')\n",
    "X_train_glove, X_val_glove, X_test_glove = vectorize_glove(df_train['Preprocessed Tweet content'], df_validation['Preprocessed Tweet content'], df_test['Preprocessed Tweet content'], glove_model)\n",
    "X_train_glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Train SVM model\n",
    "\n",
    "-using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_model_bow = train_svm_model(X_train_bow, df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using Bag Of Words\n",
      "Accuracy: 0.9218436873747495\n",
      "Confusion Matrix:\n",
      " [[ 84   3   0   5]\n",
      " [  3 115   3   4]\n",
      " [  0   3 126   5]\n",
      " [  6   4   3 135]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.90      0.91      0.91        92\n",
      "    Negative       0.92      0.92      0.92       125\n",
      "     Neutral       0.95      0.94      0.95       134\n",
      "    Positive       0.91      0.91      0.91       148\n",
      "\n",
      "    accuracy                           0.92       499\n",
      "   macro avg       0.92      0.92      0.92       499\n",
      "weighted avg       0.92      0.92      0.92       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=svm_model_bow.predict(X_test_bow)\n",
    "print(\"SVM using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "svm_model_tf_idf = train_svm_model(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using tf-idf\n",
      "Accuracy: 0.9138276553106213\n",
      "Confusion Matrix:\n",
      " [[ 83   3   1   5]\n",
      " [  4 113   4   4]\n",
      " [  0   3 128   3]\n",
      " [  8   5   3 132]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.87      0.90      0.89        92\n",
      "    Negative       0.91      0.90      0.91       125\n",
      "     Neutral       0.94      0.96      0.95       134\n",
      "    Positive       0.92      0.89      0.90       148\n",
      "\n",
      "    accuracy                           0.91       499\n",
      "   macro avg       0.91      0.91      0.91       499\n",
      "weighted avg       0.91      0.91      0.91       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=svm_model_tf_idf.predict(X_test_tfidf)\n",
    "print(\"SVM using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "svm_model_word2vec = train_svm_model(X_train_word2vec, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using word2vec\n",
      "Accuracy: 0.2685370741482966\n",
      "Confusion Matrix:\n",
      " [[  0   0  92   0]\n",
      " [  0   0 125   0]\n",
      " [  0   0 134   0]\n",
      " [  0   0 148   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00        92\n",
      "    Negative       0.00      0.00      0.00       125\n",
      "     Neutral       0.27      1.00      0.42       134\n",
      "    Positive       0.00      0.00      0.00       148\n",
      "\n",
      "    accuracy                           0.27       499\n",
      "   macro avg       0.07      0.25      0.11       499\n",
      "weighted avg       0.07      0.27      0.11       499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_test_word2vec=svm_model_word2vec.predict(X_test_word2vec)\n",
    "print(\"SVM using word2vec\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_word2vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "svm_model_glove = train_svm_model(X_train_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using glove\n",
      "Accuracy: 0.40080160320641284\n",
      "Confusion Matrix:\n",
      " [[ 3 37 22 30]\n",
      " [ 1 77 22 25]\n",
      " [ 2 45 51 36]\n",
      " [ 0 46 33 69]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.50      0.03      0.06        92\n",
      "    Negative       0.38      0.62      0.47       125\n",
      "     Neutral       0.40      0.38      0.39       134\n",
      "    Positive       0.43      0.47      0.45       148\n",
      "\n",
      "    accuracy                           0.40       499\n",
      "   macro avg       0.43      0.37      0.34       499\n",
      "weighted avg       0.42      0.40      0.37       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=svm_model_glove.predict(X_test_glove)\n",
    "print(\"SVM using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train naive bayes model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using Bag of Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "naive_bayes_model_bow = train_naive_bayes(X_train_bow, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes using Bag Of Words\n",
      "Accuracy: 0.7715430861723447\n",
      "Confusion Matrix:\n",
      " [[ 65  14   2  11]\n",
      " [  2 107   6  10]\n",
      " [  9  20  92  13]\n",
      " [  7  13   7 121]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.78      0.71      0.74        92\n",
      "    Negative       0.69      0.86      0.77       125\n",
      "     Neutral       0.86      0.69      0.76       134\n",
      "    Positive       0.78      0.82      0.80       148\n",
      "\n",
      "    accuracy                           0.77       499\n",
      "   macro avg       0.78      0.77      0.77       499\n",
      "weighted avg       0.78      0.77      0.77       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=naive_bayes_model_bow.predict(X_test_bow)\n",
    "print(\"naive bayes using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "naive_bayes_model_tf_idf = train_naive_bayes(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes using tf-idf\n",
      "Accuracy: 0.7675350701402806\n",
      "Confusion Matrix:\n",
      " [[ 54  21   2  15]\n",
      " [  0 115   2   8]\n",
      " [  2  29  86  17]\n",
      " [  4  12   4 128]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.90      0.59      0.71        92\n",
      "    Negative       0.65      0.92      0.76       125\n",
      "     Neutral       0.91      0.64      0.75       134\n",
      "    Positive       0.76      0.86      0.81       148\n",
      "\n",
      "    accuracy                           0.77       499\n",
      "   macro avg       0.81      0.75      0.76       499\n",
      "weighted avg       0.80      0.77      0.76       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=naive_bayes_model_tf_idf.predict(X_test_tfidf)\n",
    "print(\"naive bayes using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "X_train_scaled_word2vec, X_test_scaled_word2vec= scaler_data(X_train_word2vec, X_test_word2vec)\n",
    "naive_bayes_model_word2vec = train_naive_bayes(X_train_scaled_word2vec, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes using word2vec\n",
      "Accuracy: 0.250501002004008\n",
      "Confusion Matrix:\n",
      " [[  0  92   0   0]\n",
      " [  0 125   0   0]\n",
      " [  0 134   0   0]\n",
      " [  0 148   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00        92\n",
      "    Negative       0.25      1.00      0.40       125\n",
      "     Neutral       0.00      0.00      0.00       134\n",
      "    Positive       0.00      0.00      0.00       148\n",
      "\n",
      "    accuracy                           0.25       499\n",
      "   macro avg       0.06      0.25      0.10       499\n",
      "weighted avg       0.06      0.25      0.10       499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_test_word2vec=naive_bayes_model_word2vec.predict(X_test_scaled_word2vec)\n",
    "print(\"naive bayes using word2vec\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_word2vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "X_train_scaled_glove, X_test_scaled_glove= scaler_data(X_train_glove, X_test_glove)\n",
    "naive_bayes_model_glove = train_naive_bayes(X_train_scaled_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes using glove\n",
      "Accuracy: 0.2545090180360721\n",
      "Confusion Matrix:\n",
      " [[  0  92   0   0]\n",
      " [  0 125   0   0]\n",
      " [  0 134   0   0]\n",
      " [  0 146   0   2]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00        92\n",
      "    Negative       0.25      1.00      0.40       125\n",
      "     Neutral       0.00      0.00      0.00       134\n",
      "    Positive       1.00      0.01      0.03       148\n",
      "\n",
      "    accuracy                           0.25       499\n",
      "   macro avg       0.31      0.25      0.11       499\n",
      "weighted avg       0.36      0.25      0.11       499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=naive_bayes_model_glove.predict(X_test_scaled_glove)\n",
    "print(\"naive bayes using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train logistic regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using bag of words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_bow = train_logistic_regression(X_train_bow, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression using Bag Of Words\n",
      "Accuracy: 0.8997995991983968\n",
      "Confusion Matrix:\n",
      " [[ 80   3   1   8]\n",
      " [  5 113   4   3]\n",
      " [  0   5 123   6]\n",
      " [  7   5   3 133]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.87      0.87      0.87        92\n",
      "    Negative       0.90      0.90      0.90       125\n",
      "     Neutral       0.94      0.92      0.93       134\n",
      "    Positive       0.89      0.90      0.89       148\n",
      "\n",
      "    accuracy                           0.90       499\n",
      "   macro avg       0.90      0.90      0.90       499\n",
      "weighted avg       0.90      0.90      0.90       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=logistic_regression_model_bow.predict(X_test_bow)\n",
    "print(\"logistic regression using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_tf_idf = train_logistic_regression(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression using tf-idf\n",
      "Accuracy: 0.8777555110220441\n",
      "Confusion Matrix:\n",
      " [[ 77   7   2   6]\n",
      " [  4 112   5   4]\n",
      " [  7   6 117   4]\n",
      " [  8   3   5 132]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.80      0.84      0.82        92\n",
      "    Negative       0.88      0.90      0.89       125\n",
      "     Neutral       0.91      0.87      0.89       134\n",
      "    Positive       0.90      0.89      0.90       148\n",
      "\n",
      "    accuracy                           0.88       499\n",
      "   macro avg       0.87      0.87      0.87       499\n",
      "weighted avg       0.88      0.88      0.88       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=logistic_regression_model_tf_idf.predict(X_test_tfidf)\n",
    "print(\"logistic regression using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_word2vec = train_logistic_regression(X_train_word2vec, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression using word2vec\n",
      "Accuracy: 0.2685370741482966\n",
      "Confusion Matrix:\n",
      " [[  0   0  92   0]\n",
      " [  0   0 125   0]\n",
      " [  0   0 134   0]\n",
      " [  0   0 148   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00        92\n",
      "    Negative       0.00      0.00      0.00       125\n",
      "     Neutral       0.27      1.00      0.42       134\n",
      "    Positive       0.00      0.00      0.00       148\n",
      "\n",
      "    accuracy                           0.27       499\n",
      "   macro avg       0.07      0.25      0.11       499\n",
      "weighted avg       0.07      0.27      0.11       499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_test_word2vec=logistic_regression_model_word2vec.predict(X_test_word2vec)\n",
    "print(\"logistic regression using word2vec\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_word2vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FSG\\projects\\Sentiment-analysis-system\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_glove = train_logistic_regression(X_train_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression using glove\n",
      "Accuracy: 0.40480961923847697\n",
      "Confusion Matrix:\n",
      " [[ 8 31 26 27]\n",
      " [ 3 74 22 26]\n",
      " [ 3 43 53 35]\n",
      " [ 2 45 34 67]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.50      0.09      0.15        92\n",
      "    Negative       0.38      0.59      0.47       125\n",
      "     Neutral       0.39      0.40      0.39       134\n",
      "    Positive       0.43      0.45      0.44       148\n",
      "\n",
      "    accuracy                           0.40       499\n",
      "   macro avg       0.43      0.38      0.36       499\n",
      "weighted avg       0.42      0.40      0.38       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=logistic_regression_model_glove.predict(X_test_glove)\n",
    "print(\"logistic regression using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using bag of words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "knn_model_bow = train_knn(X_train_bow, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn using Bag Of Words\n",
      "Accuracy: 0.9719438877755511\n",
      "Confusion Matrix:\n",
      " [[ 88   1   0   3]\n",
      " [  0 124   0   1]\n",
      " [  3   1 129   1]\n",
      " [  2   1   1 144]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.95      0.96      0.95        92\n",
      "    Negative       0.98      0.99      0.98       125\n",
      "     Neutral       0.99      0.96      0.98       134\n",
      "    Positive       0.97      0.97      0.97       148\n",
      "\n",
      "    accuracy                           0.97       499\n",
      "   macro avg       0.97      0.97      0.97       499\n",
      "weighted avg       0.97      0.97      0.97       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_bow=knn_model_bow.predict(X_test_bow)\n",
    "print(\"knn using Bag Of Words\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using tf-idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "knn_model_tf_idf = train_knn(X_train_tfidf, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn using tf-idf\n",
      "Accuracy: 0.9458917835671342\n",
      "Confusion Matrix:\n",
      " [[ 90   1   0   1]\n",
      " [  1 123   0   1]\n",
      " [  7   1 126   0]\n",
      " [ 13   2   0 133]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.81      0.98      0.89        92\n",
      "    Negative       0.97      0.98      0.98       125\n",
      "     Neutral       1.00      0.94      0.97       134\n",
      "    Positive       0.99      0.90      0.94       148\n",
      "\n",
      "    accuracy                           0.95       499\n",
      "   macro avg       0.94      0.95      0.94       499\n",
      "weighted avg       0.95      0.95      0.95       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_tf_idf=knn_model_tf_idf.predict(X_test_tfidf)\n",
    "print(\"knn using tf-idf\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_tf_idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "knn_model_word2vec = train_knn(X_train_word2vec, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn using word2vec\n",
      "Accuracy: 0.2665330661322645\n",
      "Confusion Matrix:\n",
      " [[ 6 61 13 12]\n",
      " [10 68 18 29]\n",
      " [10 81 22 21]\n",
      " [16 72 23 37]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.14      0.07      0.09        92\n",
      "    Negative       0.24      0.54      0.33       125\n",
      "     Neutral       0.29      0.16      0.21       134\n",
      "    Positive       0.37      0.25      0.30       148\n",
      "\n",
      "    accuracy                           0.27       499\n",
      "   macro avg       0.26      0.26      0.23       499\n",
      "weighted avg       0.28      0.27      0.25       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_word2vec=knn_model_word2vec.predict(X_test_word2vec)\n",
    "print(\"knn using word2vec\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_word2vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-using glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "knn_model_glove = train_knn(X_train_glove, df_train['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn using glove\n",
      "Accuracy: 0.8637274549098196\n",
      "Confusion Matrix:\n",
      " [[ 83   1   5   3]\n",
      " [  5 116   3   1]\n",
      " [  5  12 111   6]\n",
      " [ 11  13   3 121]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.80      0.90      0.85        92\n",
      "    Negative       0.82      0.93      0.87       125\n",
      "     Neutral       0.91      0.83      0.87       134\n",
      "    Positive       0.92      0.82      0.87       148\n",
      "\n",
      "    accuracy                           0.86       499\n",
      "   macro avg       0.86      0.87      0.86       499\n",
      "weighted avg       0.87      0.86      0.86       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test_glove=knn_model_glove.predict(X_test_glove)\n",
    "print(\"knn using glove\")\n",
    "evaluate_model(df_test['sentiment'],predict_test_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using trained model for prediction on validation dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(svm + bow): 464\n"
     ]
    }
   ],
   "source": [
    "path = '../data/processed_data/'\n",
    "# df_validation.drop(columns=['Tweet content','Preprocessed Tweet content'],inplace=True)\n",
    "predict_val_bow=svm_model_bow.predict(X_val_bow)\n",
    "df_validation['predicted sentiment'] = predict_val_bow\n",
    "\n",
    "save_to_csv(df_validation, filename= path + 'validation_bow_svm.csv')\n",
    "\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(svm + bow): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(svm + tf-idf): 466\n"
     ]
    }
   ],
   "source": [
    "predict_val_tf_idf=svm_model_tf_idf.predict(X_val_tfidf)\n",
    "df_validation['predicted sentiment'] = predict_val_tf_idf\n",
    "save_to_csv(df_validation, filename= path + 'validation_tf_idf_svm.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(svm + tf-idf): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(svm + glove): 215\n"
     ]
    }
   ],
   "source": [
    "predict_val_glove=svm_model_glove.predict(X_val_glove)\n",
    "df_validation['predicted sentiment'] = predict_val_glove\n",
    "save_to_csv(df_validation, filename= path + 'validation_glove_svm.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(svm + glove): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions (svm + word2vec): 151\n"
     ]
    }
   ],
   "source": [
    "predict_val_word2vec=svm_model_word2vec.predict(X_val_word2vec)\n",
    "df_validation['predicted sentiment'] = predict_val_word2vec\n",
    "save_to_csv(df_validation, filename= path + 'validation_word2vec_svm.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions (svm + word2vec): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(logistic_regression + bow): 459\n"
     ]
    }
   ],
   "source": [
    "predict_val_bow=logistic_regression_model_bow.predict(X_val_bow)\n",
    "df_validation['predicted sentiment'] = predict_val_bow\n",
    "save_to_csv(df_validation, filename= path + 'validation_bow_lr.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(logistic_regression + bow): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(logistic_regression + tf-idf): 440\n"
     ]
    }
   ],
   "source": [
    "predict_val_tf_idf=logistic_regression_model_tf_idf.predict(X_val_tfidf)\n",
    "df_validation['predicted sentiment'] = predict_val_tf_idf\n",
    "save_to_csv(df_validation, filename= path + 'validation_tf_idf_lr.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(logistic_regression + tf-idf): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(logistic_regression + glove): 220\n"
     ]
    }
   ],
   "source": [
    "predict_val_glove=logistic_regression_model_glove.predict(X_val_glove)\n",
    "df_validation['predicted sentiment'] = predict_val_glove\n",
    "save_to_csv(df_validation, filename= path + 'validation_glove_lr.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(logistic_regression + glove): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 151\n"
     ]
    }
   ],
   "source": [
    "predict_val_word2vec=logistic_regression_model_word2vec.predict(X_val_word2vec)\n",
    "df_validation['predicted sentiment'] = predict_val_word2vec\n",
    "save_to_csv(df_validation, filename= path + 'validation_word2vec_lr.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions: {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(naive_bayes + bow): 401\n"
     ]
    }
   ],
   "source": [
    "predict_val_bow=naive_bayes_model_bow.predict(X_val_bow)\n",
    "df_validation['predicted sentiment'] = predict_val_bow\n",
    "save_to_csv(df_validation, filename= path + 'validation_bow_NB.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(naive_bayes + bow): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(naive_bayes + tf-idf): 395\n"
     ]
    }
   ],
   "source": [
    "predict_val_tf_idf=naive_bayes_model_tf_idf.predict(X_val_tfidf)\n",
    "df_validation['predicted sentiment'] = predict_val_tf_idf\n",
    "save_to_csv(df_validation, filename= path + 'validation_tf_idf_NB.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(naive_bayes + tf-idf): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(naive_bayes + glove): 164\n"
     ]
    }
   ],
   "source": [
    "predict_val_glove=naive_bayes_model_glove.predict(X_val_glove)\n",
    "df_validation['predicted sentiment'] = predict_val_glove\n",
    "save_to_csv(df_validation, filename= path + 'validation_glove_NB.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(naive_bayes + glove): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions (naive_bayes + word2vec): 140\n"
     ]
    }
   ],
   "source": [
    "predict_val_word2vec=naive_bayes_model_word2vec.predict(X_val_word2vec)\n",
    "df_validation['predicted sentiment'] = predict_val_word2vec\n",
    "save_to_csv(df_validation, filename= path + 'validation_word2vec_NB.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions (naive_bayes + word2vec): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions (knn + bow): 478\n"
     ]
    }
   ],
   "source": [
    "predict_val_bow=knn_model_bow.predict(X_val_bow)\n",
    "df_validation['predicted sentiment'] = predict_val_bow\n",
    "save_to_csv(df_validation, filename= path + 'validation_bow_KNN.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions (knn + bow): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(knn + tf-idf): 476\n"
     ]
    }
   ],
   "source": [
    "predict_val_tf_idf=knn_model_tf_idf.predict(X_val_tfidf)\n",
    "df_validation['predicted sentiment'] = predict_val_tf_idf\n",
    "save_to_csv(df_validation, filename= path + 'validation_tf_idf_KNN.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(knn + tf-idf): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions (knn + glove): 436\n"
     ]
    }
   ],
   "source": [
    "predict_val_glove=knn_model_glove.predict(X_val_glove)\n",
    "df_validation['predicted sentiment'] = predict_val_glove\n",
    "save_to_csv(df_validation, filename= path + 'validation_glove_KNN.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions (knn + glove): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions(knn + word2vec): 128\n"
     ]
    }
   ],
   "source": [
    "predict_val_word2vec=knn_model_word2vec.predict(X_val_word2vec)\n",
    "df_validation['predicted sentiment'] = predict_val_word2vec\n",
    "save_to_csv(df_validation, filename= path + 'validation_word2vec_KNN.csv')\n",
    "equal_count = (df_validation['predicted sentiment'] == df_validation['sentiment']).sum()\n",
    "print(f\"Number of correct predictions(knn + word2vec): {equal_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
